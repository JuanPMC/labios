################################################################################
Memcached config
################################################################################
- libevent is a dependency : apt-get install libevent-dev
- Change in src code(forcing our own data distribution to specific server):
- copy into libmemcached/get.cc:236
    "master_server_key=atoi(group_key);"
- copy into libmemcached/storage.cc:375
    "uint32_t server_key=  atoi(group_key);"
- install from source
    ./configure && make && sudo make install

How to use:
- Specify group_key to be the actual number of the server.
- Example: If you want to use server #0, you set the key to "0" and so on
options to start servers:
    -m: how much RAM to use for item storage (in megabytes) (min is 64MB)
    -d: run it as daemon
    -p: port that listens



################################################################################
TODO LIST
################################################################################
-Experiment with suspend/wake on Lan

-Request Distribution:
How
o   Irrelevant to MT
o   File aware

Where
o   Random Selection(File, Node Status-Alive/Suspended)
o   Based on File
o   Based on Alive/Suspended

-Overhead of Oversubscribing the core.
Â·        Test program to check this
COMMUNICATION
- Current is mpi_send - mpi_recv with listeners
- Try one-sided communication instead of listeners
- queue in memcached - api-request : who sent request, Porus client serves
directly {all entries to the queue will be happening in parallel}

May 16th, 2017
- Program repo
    - Resides on the workers
    - Have ID for each program
    - Each program is responsible to update the global task list with status
    and data
    - User defined programs need to pre-compiled and get an exe_ID from
    config_manager
- Memcached
    - Use Memcached as a global DB
    - Local and global structures reside here
        - Memtables
        - Worker status
        - User's file metadata info
        - Task queue
        - Global cache (prefetch, hot data) group_by_key
- API (each rank)
    - Write
        - Accepts data, passes it to RH
    - Read
        - Passes requests to RH and waits on the task queue to get the data
- Porus Client
    - RH
        - Builds requests:
            1) aggregated: global cache, pass the request to specific
            memcached server by either hashing or via global MDM
            2) local: Simply send the request to TS
    - TS
        - Approaches to serve requests:
            1) Direct schedule it to task queue
            2) Cache it in the Memtable and flush it later MEmtable
            map<req_id,{request}>
                - Flushing:
                    - Aggregates all the requests
                    - Consults RD to get the distribution of each request
                    - Builds the tasks for all the workers
                    - Queues them inside the task queue
            map<task_id,{task}> = 5
    - RD
        - Uses the worker status and MDM info to perform min/max
        - Manages the workers (waking up)
        - For each request returns which specific workers to use
    - MDM
        - Manages all metadata info by using memcached
            - user's filenames
            - local files that consist the file
            - location on workers
            - replicas
            - cached
            - invalidation stuff
            - locking mechanisms
        - Persists all memory structures on MPI_Finalize on PFS (serialize LIB)

-Workers
    - Upon waking up executes tasks depending on self queue FCFS
    - Upon finishing all tasks after timer expires it suspends
    - Could perform periodically replication and data re-organization
-Tasks
    -Worker_read
    -Worker_write
    -User's programs
    -Predefined exes(sort, compress)
    -PFS_read
    -PFS_write
    -Delete
    -Rename
    -Copy
    -Move

################################################################################
TODO TASKS(may25th)
################################################################################
- Memcached(done)
- MDM apis (done)
- Fill out posix.cpp (done)
- RH
    - Finish handle()
- TS
    -
- RD


MDM:
filename:string
mode:string
fh:File*

filename:
chunks [ {primary , cached,invalid, ,replicas}]
chunk:{filename,offset,size,location}

- we check if fh exist                                          1
- on read and write we check mode                               2
- fclose delete fh and mode                                     1,2
- read checks chunks with its replica                           1,3,4,5,6,7
- on flush we update chunks                                     1,3,4
- prefetcher amd cache manager on evict update chunk cache flag
- relica process updates replicas

Add prefix for all the following "tables" for logically abstracting the
keyspace:
- hash filenames to uint32_t and get a file_ID
0. {file_ID, size_t}
1. {file_ID,fh},{fh,file_ID}
2. {fh,mode}
3. {fh, fp}
4. {file_ID,chunk_ids}
5. {chunk_id,chunk}
6. {chunk_id,is_cached}
7. {chunk_id,[replica_ids]}
8. {replica_id,replica}
9. {file_id, chunk_ids_invalid}

24 Ranks
8 Porus Clients
8 Memcached Server
server list of 8 Servers with each server having a group key


flatbuffers::FlatBufferBuilder builder(sizeof(int)+sizeof(long)+sizeof
        (uint)+sizeof(int));
    auto offset = mdm_posix->get_fp(file_id);
    auto request = posix_api_request(builder, READ, offset,(size * count),
                                   file_id);
    builder.Finish(request);
    uint8_t *flatbuff = builder.GetBufferPointer();
    int flatbuff_size = builder.GetSize();
    std::string send_buff((char*)flatbuff);

    std::string id = std::to_string(WRITE) + SEPARATOR +
                     std::to_string(mdm_posix->get_filename(file_id)) +
                     SEPARATOR + std::to_string(offset) + SEPARATOR +
                     std::to_string(size*count);
    memcached_client::getInstance()->put(id, send_buff,REQUEST_SPACE);


GCL queue
-http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0260r0.html#queue_order

